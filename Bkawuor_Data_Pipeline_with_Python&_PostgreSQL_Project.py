# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BhFpuqtwgFQt-43eFGZ76YqnES25rMHi

# Predicting Equipment Failure and Scheduling Maintenance Proactively

## Problem Statement

Equipment failure is a major cause of downtime in the telecommunications industry, which can result in significant financial losses and customer dissatisfaction. To minimize downtime and ensure optimal performance, it is crucial to identify potential equipment failures and schedule
maintenance accordingly proactively.

This requires the collection and analysis of large amounts of data generated by various equipment and network sensors.
The deliverable for this project is a data pipeline that can efficiently collect, clean, and analyze equipment and network sensor data. The pipeline should be designed to identify potential
equipment failures and schedule maintenance proactively, minimizing downtime and improving overall equipment performance.

The data pipeline will be built using Python and PostgreSQL and with the Postgres database hosted on Google Cloud.
"""

#Installing Required Libraries

!pip install psycopg2-binary

#importing pandas and python module for Postgre SQL
import pandas as pd
from sqlalchemy import create_engine

#Obtaining Google Cloud PostgreSQL Connection Details

POSTGRES_ADDRESS = '157.245.102.81'
POSTGRES_PORT = '5432'
POSTGRES_DBNAME = 'dq'
POSTGRES_USERNAME = 'postgres'
POSTGRES_PASSWORD = 'E*3b8km$dpmRLLuf1Rs$'

# Define the database engine
postgres_str = ('postgresql://{username}:{password}@{ipaddress}:{port}/{dbname}'
                .format(username=POSTGRES_USERNAME,
                        password=POSTGRES_PASSWORD,
                        ipaddress=POSTGRES_ADDRESS,
                        port=POSTGRES_PORT,
                        dbname=POSTGRES_DBNAME))
engine = create_engine(postgres_str)

#Data Extraction

def extract_data():
    # Load the equipment sensor data
    equipment_data = pd.read_csv('equipment_sensor.csv')

    # Load the network sensor data
    network_data = pd.read_csv('network_sensor.csv')

    # Load the maintenance records data
    maintenance_data = pd.read_csv('maintenance_records.csv')

    return equipment_data, network_data, maintenance_data

#Transform Data

def transform_data(equipment_data, network_data, maintenance_data):
    # Remove duplicates
    equipment_data.drop_duplicates(inplace=True)
    network_data.drop_duplicates(inplace=True)
    maintenance_data.drop_duplicates(inplace=True)

    # Correct Missing data
    equipment_data.fillna(method='ffill', inplace=True)
    network_data.fillna(method='ffill', inplace=True)
    maintenance_data.fillna(method='ffill', inplace=True)

    # Achieve data consistency
    equipment_data['date_time'] = pd.to_datetime(equipment_data['date'] + ' ' + equipment_data['time'])
    equipment_data.drop(['date', 'time'], axis=1, inplace=True)

    network_data['date_time'] = pd.to_datetime(network_data['date'] + ' ' + network_data['time'])
    network_data.drop(['date', 'time'], axis=1, inplace=True)

    maintenance_data['date_time'] = pd.to_datetime(maintenance_data['date'] + ' ' + maintenance_data['time'])
    maintenance_data.drop(['date', 'time'], axis=1, inplace=True)

    # Aggregate the data
    equipment_summary = equipment_data.groupby('ID').agg({'date_time': ['min', 'max'], 'sensor_reading': ['mean', 'max']})
    equipment_summary.columns = ['first_seen', 'last_seen', 'average_reading', 'max_reading']
    network_summary = network_data.groupby('ID').agg({'date_time': ['min', 'max'], 'sensor_reading': ['mean', 'max']})
    network_summary.columns = ['first_seen', 'last_seen', 'average_reading', 'max_reading']

    # Join the data
    sensor_summary = pd.merge(equipment_summary, network_summary, how='outer', left_index=True, right_index=True)
    sensor_summary = sensor_summary.reset_index()
    sensor_summary = sensor_summary.rename(columns={'ID': 'equipment_ID'})

    maintenance_data = maintenance_data[['date_time', 'equipment_ID', 'maintenance_type']]

    return sensor_summary, maintenance_data

#Load data and define main function

def load_data(sensor_summary, maintenance_df):
    # Load the data to PostgreSQL
    sensor_summary.to_sql('sensor_summary', engine, if_exists='replace')
    maintenance_df.to_sql('maintenance_records', engine, if_exists='replace')

def main():
    equipment_data, network_data, maintenance_data = extract_data()
    sensor_summary, maintenance_df = transform_data(equipment_data, network_data, maintenance_data)
    load_data(sensor_summary, maintenance_df)

if __name__ == '__main__':
    main()